---
title: 如何选择 ML.NET 算法
description: 了解如何为机器学习模型选择 ML.NET 算法
ms.topic: overview
ms.date: 06/05/2019
ms.openlocfilehash: 04cf191401c7c25f1fa341acaf9312dc19752260
ms.sourcegitcommit: e301979e3049ce412d19b094c60ed95b316a8f8c
ms.translationtype: HT
ms.contentlocale: zh-CN
ms.lasthandoff: 12/16/2020
ms.locfileid: "97593085"
---
# <a name="how-to-choose-an-mlnet-algorithm"></a><span data-ttu-id="61cae-103">如何选择 ML.NET 算法</span><span class="sxs-lookup"><span data-stu-id="61cae-103">How to choose an ML.NET algorithm</span></span>

<span data-ttu-id="61cae-104">对于每个 [ML.NET 任务](resources/tasks.md)，有多种训练算法可供选择。</span><span class="sxs-lookup"><span data-stu-id="61cae-104">For each [ML.NET task](resources/tasks.md), there are multiple training algorithms to choose from.</span></span> <span data-ttu-id="61cae-105">选择哪个算法取决于尝试解决的问题、数据的特征以及可用的计算和存储资源。</span><span class="sxs-lookup"><span data-stu-id="61cae-105">Which one to choose depends on the problem you are trying to solve, the characteristics of your data, and the compute and storage resources you have available.</span></span> <span data-ttu-id="61cae-106">值得注意的是，训练机器学习模型是一个迭代过程。</span><span class="sxs-lookup"><span data-stu-id="61cae-106">It is important to note that training a machine learning model is an iterative process.</span></span> <span data-ttu-id="61cae-107">可能需要尝试多种算法才能找到效果最好的算法。</span><span class="sxs-lookup"><span data-stu-id="61cae-107">You might need to try multiple algorithms to find the one that works best.</span></span>

<span data-ttu-id="61cae-108">算法在 **特征** 上运行。</span><span class="sxs-lookup"><span data-stu-id="61cae-108">Algorithms operate on **features**.</span></span> <span data-ttu-id="61cae-109">特征是根据输入数据进行计算的数字值。</span><span class="sxs-lookup"><span data-stu-id="61cae-109">Features are numerical values computed from your input data.</span></span> <span data-ttu-id="61cae-110">它们是机器学习算法的最佳输入。</span><span class="sxs-lookup"><span data-stu-id="61cae-110">They are optimal inputs for machine learning algorithms.</span></span> <span data-ttu-id="61cae-111">可以使用一个或多个[数据转换](resources/transforms.md)将原始输入数据转换为特征。</span><span class="sxs-lookup"><span data-stu-id="61cae-111">You transform your raw input data into features using one or more [data transforms](resources/transforms.md).</span></span> <span data-ttu-id="61cae-112">例如，文本数据被转换为一组字词计数和字词组合计数。</span><span class="sxs-lookup"><span data-stu-id="61cae-112">For example, text data is transformed into a set of word counts and word combination counts.</span></span> <span data-ttu-id="61cae-113">使用数据转换从原始数据类型中提取特征后，它们被称为 **特征化**。</span><span class="sxs-lookup"><span data-stu-id="61cae-113">Once the features have been extracted from a raw data type using data transforms, they are referred to as **featurized**.</span></span> <span data-ttu-id="61cae-114">例如，特征化文本或特征化图像数据。</span><span class="sxs-lookup"><span data-stu-id="61cae-114">For example, featurized text, or featurized image data.</span></span>

## <a name="trainer--algorithm--task"></a><span data-ttu-id="61cae-115">训练程序 = 算法 + 任务</span><span class="sxs-lookup"><span data-stu-id="61cae-115">Trainer = Algorithm + Task</span></span>

<span data-ttu-id="61cae-116">算法是执行后可生成 **模型** 的数学运算。</span><span class="sxs-lookup"><span data-stu-id="61cae-116">An algorithm is the math that executes to produce a **model**.</span></span> <span data-ttu-id="61cae-117">不同的算法生成具有不同特征的模型。</span><span class="sxs-lookup"><span data-stu-id="61cae-117">Different algorithms produce models with different characteristics.</span></span>

<span data-ttu-id="61cae-118">借助 ML.NET，同一算法可以应用于不同的任务。</span><span class="sxs-lookup"><span data-stu-id="61cae-118">With ML.NET, the same algorithm can be applied to different tasks.</span></span> <span data-ttu-id="61cae-119">例如，随机双坐标上升可用于二元分类、多类分类和回归。</span><span class="sxs-lookup"><span data-stu-id="61cae-119">For example, Stochastic Dual Coordinate Ascent can be used for Binary Classification, Multiclass Classification, and Regression.</span></span> <span data-ttu-id="61cae-120">区别在于如何解释算法的输出来匹配任务。</span><span class="sxs-lookup"><span data-stu-id="61cae-120">The difference is in how the output of the algorithm is interpreted to match the task.</span></span>

<span data-ttu-id="61cae-121">对于每种算法/任务组合，ML.NET 都提供用于执行训练算法并进行解释的组件。</span><span class="sxs-lookup"><span data-stu-id="61cae-121">For each algorithm/task combination, ML.NET provides a component that executes the training algorithm and makes the interpretation.</span></span> <span data-ttu-id="61cae-122">这些组件称为训练程序。</span><span class="sxs-lookup"><span data-stu-id="61cae-122">These components are called trainers.</span></span> <span data-ttu-id="61cae-123">例如，<xref:Microsoft.ML.Trainers.SdcaRegressionTrainer> 使用应用于 **回归** 任务的 **StochasticDualCoordinatedAscent** 算法。</span><span class="sxs-lookup"><span data-stu-id="61cae-123">For example, the <xref:Microsoft.ML.Trainers.SdcaRegressionTrainer> uses the **StochasticDualCoordinatedAscent** algorithm applied to the **Regression** task.</span></span>

## <a name="linear-algorithms"></a><span data-ttu-id="61cae-124">线性算法</span><span class="sxs-lookup"><span data-stu-id="61cae-124">Linear algorithms</span></span>

<span data-ttu-id="61cae-125">线性算法生成一个模型，该模型根据输入数据和一组 **权重** 的线性组合计算 **分数**。</span><span class="sxs-lookup"><span data-stu-id="61cae-125">Linear algorithms produce a model that calculates **scores** from a linear combination of the input data and a set of **weights**.</span></span> <span data-ttu-id="61cae-126">权重是训练期间估算的模型参数。</span><span class="sxs-lookup"><span data-stu-id="61cae-126">The weights are parameters of the model estimated during training.</span></span>

<span data-ttu-id="61cae-127">线性算法适用于[线性可分](https://en.wikipedia.org/wiki/Linear_separability)的特征。</span><span class="sxs-lookup"><span data-stu-id="61cae-127">Linear algorithms work well for features that are [linearly separable](https://en.wikipedia.org/wiki/Linear_separability).</span></span>

<span data-ttu-id="61cae-128">在使用线性算法进行训练之前，应对特征进行规范化。</span><span class="sxs-lookup"><span data-stu-id="61cae-128">Before training with a linear algorithm, the features should be normalized.</span></span> <span data-ttu-id="61cae-129">这样可防止某个特征对结果产生比其他特征更多的影响。</span><span class="sxs-lookup"><span data-stu-id="61cae-129">This prevents one feature from having more influence over the result than others.</span></span>

<span data-ttu-id="61cae-130">一般而言，线性算法可缩放且速度快，训练和预测费用也很低。</span><span class="sxs-lookup"><span data-stu-id="61cae-130">In general, linear algorithms are scalable, fast, cheap to train, and cheap to predict.</span></span> <span data-ttu-id="61cae-131">它们按特征数量进行缩放，并按训练数据集的大小粗略进行缩放。</span><span class="sxs-lookup"><span data-stu-id="61cae-131">They scale by the number of features and approximately by the size of the training data set.</span></span>

<span data-ttu-id="61cae-132">线性算法对训练数据进行多次传递。</span><span class="sxs-lookup"><span data-stu-id="61cae-132">Linear algorithms make multiple passes over the training data.</span></span> <span data-ttu-id="61cae-133">如果数据集适用于内存，则在追加训练程序之前向 ML.NET 管道添加[缓存检查点](xref:Microsoft.ML.LearningPipelineExtensions.AppendCacheCheckpoint%2A)将使训练运行速度加快。</span><span class="sxs-lookup"><span data-stu-id="61cae-133">If your dataset fits into memory, then adding a [cache checkpoint](xref:Microsoft.ML.LearningPipelineExtensions.AppendCacheCheckpoint%2A) to your ML.NET pipeline before appending the trainer will make the training run faster.</span></span>

<span data-ttu-id="61cae-134">**线性训练程序**</span><span class="sxs-lookup"><span data-stu-id="61cae-134">**Linear Trainers**</span></span>

|<span data-ttu-id="61cae-135">算法</span><span class="sxs-lookup"><span data-stu-id="61cae-135">Algorithm</span></span>|<span data-ttu-id="61cae-136">属性</span><span class="sxs-lookup"><span data-stu-id="61cae-136">Properties</span></span>|<span data-ttu-id="61cae-137">训练程序</span><span class="sxs-lookup"><span data-stu-id="61cae-137">Trainers</span></span>|
|---------|----------|--------|
|<span data-ttu-id="61cae-138">平均感知器</span><span class="sxs-lookup"><span data-stu-id="61cae-138">Averaged perceptron</span></span>|<span data-ttu-id="61cae-139">最适合用于文本分类</span><span class="sxs-lookup"><span data-stu-id="61cae-139">Best for text classification</span></span>|<xref:Microsoft.ML.Trainers.AveragedPerceptronTrainer>|
|<span data-ttu-id="61cae-140">随机双坐标上升</span><span class="sxs-lookup"><span data-stu-id="61cae-140">Stochastic dual coordinated ascent</span></span>|<span data-ttu-id="61cae-141">默认性能良好，不需要调整</span><span class="sxs-lookup"><span data-stu-id="61cae-141">Tuning not needed for good default performance</span></span>|<span data-ttu-id="61cae-142"><xref:Microsoft.ML.Trainers.SdcaLogisticRegressionBinaryTrainer> <xref:Microsoft.ML.Trainers.SdcaNonCalibratedBinaryTrainer> <xref:Microsoft.ML.Trainers.SdcaMaximumEntropyMulticlassTrainer> <xref:Microsoft.ML.Trainers.SdcaNonCalibratedMulticlassTrainer> <xref:Microsoft.ML.Trainers.SdcaRegressionTrainer></span><span class="sxs-lookup"><span data-stu-id="61cae-142"><xref:Microsoft.ML.Trainers.SdcaLogisticRegressionBinaryTrainer> <xref:Microsoft.ML.Trainers.SdcaNonCalibratedBinaryTrainer> <xref:Microsoft.ML.Trainers.SdcaMaximumEntropyMulticlassTrainer> <xref:Microsoft.ML.Trainers.SdcaNonCalibratedMulticlassTrainer> <xref:Microsoft.ML.Trainers.SdcaRegressionTrainer></span></span>|
|<span data-ttu-id="61cae-143">L-BFGS</span><span class="sxs-lookup"><span data-stu-id="61cae-143">L-BFGS</span></span>|<span data-ttu-id="61cae-144">在有大量特征时使用。</span><span class="sxs-lookup"><span data-stu-id="61cae-144">Use when number of features is large.</span></span> <span data-ttu-id="61cae-145">生成逻辑回归训练统计数据，但缩放性能不如 AveragedPerceptronTrainer</span><span class="sxs-lookup"><span data-stu-id="61cae-145">Produces logistic regression training statistics, but doesn't scale as well as the AveragedPerceptronTrainer</span></span>|<span data-ttu-id="61cae-146"><xref:Microsoft.ML.Trainers.LbfgsLogisticRegressionBinaryTrainer> <xref:Microsoft.ML.Trainers.LbfgsMaximumEntropyMulticlassTrainer> <xref:Microsoft.ML.Trainers.LbfgsPoissonRegressionTrainer></span><span class="sxs-lookup"><span data-stu-id="61cae-146"><xref:Microsoft.ML.Trainers.LbfgsLogisticRegressionBinaryTrainer> <xref:Microsoft.ML.Trainers.LbfgsMaximumEntropyMulticlassTrainer> <xref:Microsoft.ML.Trainers.LbfgsPoissonRegressionTrainer></span></span>|
|<span data-ttu-id="61cae-147">符号随机梯度下降</span><span class="sxs-lookup"><span data-stu-id="61cae-147">Symbolic stochastic gradient descent</span></span>|<span data-ttu-id="61cae-148">最快速、最准确的线性二元分类训练程序。</span><span class="sxs-lookup"><span data-stu-id="61cae-148">Fastest and most accurate linear binary classification trainer.</span></span> <span data-ttu-id="61cae-149">可随处理器数量很好地缩放</span><span class="sxs-lookup"><span data-stu-id="61cae-149">Scales well with number of processors</span></span>|<xref:Microsoft.ML.Trainers.SymbolicSgdLogisticRegressionBinaryTrainer>|

## <a name="decision-tree-algorithms"></a><span data-ttu-id="61cae-150">决策树算法</span><span class="sxs-lookup"><span data-stu-id="61cae-150">Decision tree algorithms</span></span>

<span data-ttu-id="61cae-151">决策树算法创建包含一系列决策的模型：实际上是包含数据值的流程图。</span><span class="sxs-lookup"><span data-stu-id="61cae-151">Decision tree algorithms create a model that contains a series of decisions: effectively a flow chart through the data values.</span></span>

<span data-ttu-id="61cae-152">特征不需要线性可分即可使用此类算法。</span><span class="sxs-lookup"><span data-stu-id="61cae-152">Features do not need to be linearly separable to use this type of algorithm.</span></span> <span data-ttu-id="61cae-153">特征无需规范化，因为特征向量中的各个值在决策过程中独立使用。</span><span class="sxs-lookup"><span data-stu-id="61cae-153">And features do not need to be normalized, because the individual values in the feature vector are used independently in the decision process.</span></span>

<span data-ttu-id="61cae-154">决策树算法通常非常准确。</span><span class="sxs-lookup"><span data-stu-id="61cae-154">Decision tree algorithms are generally very accurate.</span></span>

<span data-ttu-id="61cae-155">除广义加性模型 (GAM) 之外，在存在大量特征的情况下，树模型可能缺少可解释性。</span><span class="sxs-lookup"><span data-stu-id="61cae-155">Except for Generalized Additive Models (GAMs), tree models can lack explainability when the number of features is large.</span></span>

<span data-ttu-id="61cae-156">决策树算法需要更多资源，并且缩放性能不如线性算法。</span><span class="sxs-lookup"><span data-stu-id="61cae-156">Decision tree algorithms take more resources and do not scale as well as linear ones do.</span></span> <span data-ttu-id="61cae-157">它们在适用于内存的数据集中拥有良好性能。</span><span class="sxs-lookup"><span data-stu-id="61cae-157">They do perform well on datasets that can fit into memory.</span></span>

<span data-ttu-id="61cae-158">提升决策树是一组小型决策树，其中每个决策树对输入数据进行评分并将分数传递到下一个决策树来生成更好的分数，以此类推，其中每个决策树都会在之前决策树的基础上有所改进。</span><span class="sxs-lookup"><span data-stu-id="61cae-158">Boosted decision trees are an ensemble of small trees where each tree scores the input data and passes the score onto the next tree to produce a better score, and so on, where each tree in the ensemble improves on the previous.</span></span>

<span data-ttu-id="61cae-159">**决策树训练程序**</span><span class="sxs-lookup"><span data-stu-id="61cae-159">**Decision tree trainers**</span></span>

|<span data-ttu-id="61cae-160">算法</span><span class="sxs-lookup"><span data-stu-id="61cae-160">Algorithm</span></span>|<span data-ttu-id="61cae-161">属性</span><span class="sxs-lookup"><span data-stu-id="61cae-161">Properties</span></span>|<span data-ttu-id="61cae-162">训练程序</span><span class="sxs-lookup"><span data-stu-id="61cae-162">Trainers</span></span>|
|---------|----------|--------|
|<span data-ttu-id="61cae-163">轻型梯度增强机</span><span class="sxs-lookup"><span data-stu-id="61cae-163">Light gradient boosted machine</span></span>|<span data-ttu-id="61cae-164">最快速、最准确的二元分类树训练程序。</span><span class="sxs-lookup"><span data-stu-id="61cae-164">Fastest and most accurate of the binary classification tree trainers.</span></span> <span data-ttu-id="61cae-165">高度可调</span><span class="sxs-lookup"><span data-stu-id="61cae-165">Highly tunable</span></span>|<span data-ttu-id="61cae-166"><xref:Microsoft.ML.Trainers.LightGbm.LightGbmBinaryTrainer> <xref:Microsoft.ML.Trainers.LightGbm.LightGbmMulticlassTrainer> <xref:Microsoft.ML.Trainers.LightGbm.LightGbmRegressionTrainer> <xref:Microsoft.ML.Trainers.LightGbm.LightGbmRankingTrainer></span><span class="sxs-lookup"><span data-stu-id="61cae-166"><xref:Microsoft.ML.Trainers.LightGbm.LightGbmBinaryTrainer> <xref:Microsoft.ML.Trainers.LightGbm.LightGbmMulticlassTrainer> <xref:Microsoft.ML.Trainers.LightGbm.LightGbmRegressionTrainer> <xref:Microsoft.ML.Trainers.LightGbm.LightGbmRankingTrainer></span></span>|
|<span data-ttu-id="61cae-167">快速决策树</span><span class="sxs-lookup"><span data-stu-id="61cae-167">Fast tree</span></span>|<span data-ttu-id="61cae-168">用于特征化图像数据。</span><span class="sxs-lookup"><span data-stu-id="61cae-168">Use for featurized image data.</span></span> <span data-ttu-id="61cae-169">在非均衡数据方面具有弹性。</span><span class="sxs-lookup"><span data-stu-id="61cae-169">Resilient to unbalanced data.</span></span> <span data-ttu-id="61cae-170">高度可调</span><span class="sxs-lookup"><span data-stu-id="61cae-170">Highly tunable</span></span> | <span data-ttu-id="61cae-171"><xref:Microsoft.ML.Trainers.FastTree.FastTreeBinaryTrainer> <xref:Microsoft.ML.Trainers.FastTree.FastTreeRegressionTrainer> <xref:Microsoft.ML.Trainers.FastTree.FastTreeTweedieTrainer> <xref:Microsoft.ML.Trainers.FastTree.FastTreeRankingTrainer></span><span class="sxs-lookup"><span data-stu-id="61cae-171"><xref:Microsoft.ML.Trainers.FastTree.FastTreeBinaryTrainer> <xref:Microsoft.ML.Trainers.FastTree.FastTreeRegressionTrainer> <xref:Microsoft.ML.Trainers.FastTree.FastTreeTweedieTrainer> <xref:Microsoft.ML.Trainers.FastTree.FastTreeRankingTrainer></span></span>|
|<span data-ttu-id="61cae-172">快速林</span><span class="sxs-lookup"><span data-stu-id="61cae-172">Fast forest</span></span>|<span data-ttu-id="61cae-173">适用于干扰性数据</span><span class="sxs-lookup"><span data-stu-id="61cae-173">Works well with noisy data</span></span>|<span data-ttu-id="61cae-174"><xref:Microsoft.ML.Trainers.FastTree.FastForestBinaryTrainer> <xref:Microsoft.ML.Trainers.FastTree.FastForestRegressionTrainer></span><span class="sxs-lookup"><span data-stu-id="61cae-174"><xref:Microsoft.ML.Trainers.FastTree.FastForestBinaryTrainer> <xref:Microsoft.ML.Trainers.FastTree.FastForestRegressionTrainer></span></span>|
|<span data-ttu-id="61cae-175">广义加性模型 (GAM)</span><span class="sxs-lookup"><span data-stu-id="61cae-175">Generalized additive model (GAM)</span></span>|<span data-ttu-id="61cae-176">最适合用于使用决策树算法时表现良好但可解释性为优先事项的问题</span><span class="sxs-lookup"><span data-stu-id="61cae-176">Best for problems that perform well with tree algorithms but where explainability is a priority</span></span>|<span data-ttu-id="61cae-177"><xref:Microsoft.ML.Trainers.FastTree.GamBinaryTrainer> <xref:Microsoft.ML.Trainers.FastTree.GamRegressionTrainer></span><span class="sxs-lookup"><span data-stu-id="61cae-177"><xref:Microsoft.ML.Trainers.FastTree.GamBinaryTrainer> <xref:Microsoft.ML.Trainers.FastTree.GamRegressionTrainer></span></span>|

## <a name="matrix-factorization"></a><span data-ttu-id="61cae-178">矩阵分解</span><span class="sxs-lookup"><span data-stu-id="61cae-178">Matrix factorization</span></span>

|<span data-ttu-id="61cae-179">属性</span><span class="sxs-lookup"><span data-stu-id="61cae-179">Properties</span></span>|<span data-ttu-id="61cae-180">训练程序</span><span class="sxs-lookup"><span data-stu-id="61cae-180">Trainers</span></span>|
|----------|--------|
|<span data-ttu-id="61cae-181">最适合用于具有大型数据集的稀疏分类数据</span><span class="sxs-lookup"><span data-stu-id="61cae-181">Best for sparse categorical data, with large datasets</span></span>|<xref:Microsoft.ML.Trainers.FieldAwareFactorizationMachineTrainer>|

## <a name="meta-algorithms"></a><span data-ttu-id="61cae-182">元算法</span><span class="sxs-lookup"><span data-stu-id="61cae-182">Meta algorithms</span></span>

<span data-ttu-id="61cae-183">这些训练程序根据二元训练程序创建多类训练程序。</span><span class="sxs-lookup"><span data-stu-id="61cae-183">These trainers create a multiclass trainer from a binary trainer.</span></span> <span data-ttu-id="61cae-184">与 <xref:Microsoft.ML.Trainers.AveragedPerceptronTrainer>、<xref:Microsoft.ML.Trainers.LbfgsLogisticRegressionBinaryTrainer>、<xref:Microsoft.ML.Trainers.SymbolicSgdLogisticRegressionBinaryTrainer>、<xref:Microsoft.ML.Trainers.LightGbm.LightGbmBinaryTrainer>、<xref:Microsoft.ML.Trainers.FastTree.FastTreeBinaryTrainer>、<xref:Microsoft.ML.Trainers.FastTree.FastForestBinaryTrainer>、<xref:Microsoft.ML.Trainers.FastTree.GamBinaryTrainer> 配合使用。</span><span class="sxs-lookup"><span data-stu-id="61cae-184">Use with <xref:Microsoft.ML.Trainers.AveragedPerceptronTrainer>, <xref:Microsoft.ML.Trainers.LbfgsLogisticRegressionBinaryTrainer>, <xref:Microsoft.ML.Trainers.SymbolicSgdLogisticRegressionBinaryTrainer>, <xref:Microsoft.ML.Trainers.LightGbm.LightGbmBinaryTrainer>, <xref:Microsoft.ML.Trainers.FastTree.FastTreeBinaryTrainer>, <xref:Microsoft.ML.Trainers.FastTree.FastForestBinaryTrainer>, <xref:Microsoft.ML.Trainers.FastTree.GamBinaryTrainer>.</span></span>

|<span data-ttu-id="61cae-185">算法</span><span class="sxs-lookup"><span data-stu-id="61cae-185">Algorithm</span></span>|<span data-ttu-id="61cae-186">属性</span><span class="sxs-lookup"><span data-stu-id="61cae-186">Properties</span></span>|<span data-ttu-id="61cae-187">训练程序</span><span class="sxs-lookup"><span data-stu-id="61cae-187">Trainers</span></span>|
|---------|----------|--------|
|<span data-ttu-id="61cae-188">一对多</span><span class="sxs-lookup"><span data-stu-id="61cae-188">One versus all</span></span>|<span data-ttu-id="61cae-189">此多类分类器为每个类训练一个二元分类器，这可将该类与所有其他类区分开来。</span><span class="sxs-lookup"><span data-stu-id="61cae-189">This multiclass classifier trains one binary classifier for each class, which distinguishes that class from all other classes.</span></span> <span data-ttu-id="61cae-190">规模因要分类的类的数量而受到限制</span><span class="sxs-lookup"><span data-stu-id="61cae-190">Is limited in scale by the number of classes to categorize</span></span>|[<span data-ttu-id="61cae-191">OneVersusAllTrainer\<BinaryClassificationTrainer></span><span class="sxs-lookup"><span data-stu-id="61cae-191">OneVersusAllTrainer\<BinaryClassificationTrainer></span></span>](xref:Microsoft.ML.Trainers.OneVersusAllTrainer) |
|<span data-ttu-id="61cae-192">成对耦合</span><span class="sxs-lookup"><span data-stu-id="61cae-192">Pairwise coupling</span></span>|<span data-ttu-id="61cae-193">此多类分类器在每对类上训练二元分类算法。</span><span class="sxs-lookup"><span data-stu-id="61cae-193">This multiclass classifier trains a binary classification algorithm on each pair of classes.</span></span> <span data-ttu-id="61cae-194">规模因类的数量而受到限制，因为必须训练每个两个类的组合。</span><span class="sxs-lookup"><span data-stu-id="61cae-194">Is limited in scale by the number of classes, as each combination of two classes must be trained.</span></span>|[<span data-ttu-id="61cae-195">PairwiseCouplingTrainer\<BinaryClassificationTrainer></span><span class="sxs-lookup"><span data-stu-id="61cae-195">PairwiseCouplingTrainer\<BinaryClassificationTrainer></span></span>](xref:Microsoft.ML.Trainers.PairwiseCouplingTrainer)|

## <a name="k-means"></a><span data-ttu-id="61cae-196">K-Means</span><span class="sxs-lookup"><span data-stu-id="61cae-196">K-Means</span></span>

|<span data-ttu-id="61cae-197">属性</span><span class="sxs-lookup"><span data-stu-id="61cae-197">Properties</span></span>|<span data-ttu-id="61cae-198">训练程序</span><span class="sxs-lookup"><span data-stu-id="61cae-198">Trainers</span></span>|
|----------|--------|
|<span data-ttu-id="61cae-199">用于聚类分析</span><span class="sxs-lookup"><span data-stu-id="61cae-199">Use for clustering</span></span>|<xref:Microsoft.ML.Trainers.KMeansTrainer>|

## <a name="principal-component-analysis"></a><span data-ttu-id="61cae-200">主体组件分析</span><span class="sxs-lookup"><span data-stu-id="61cae-200">Principal component analysis</span></span>

|<span data-ttu-id="61cae-201">属性</span><span class="sxs-lookup"><span data-stu-id="61cae-201">Properties</span></span>|<span data-ttu-id="61cae-202">训练程序</span><span class="sxs-lookup"><span data-stu-id="61cae-202">Trainers</span></span>|
|----------|--------|
|<span data-ttu-id="61cae-203">用于异常情况检测</span><span class="sxs-lookup"><span data-stu-id="61cae-203">Use for anomaly detection</span></span>|<xref:Microsoft.ML.Trainers.RandomizedPcaTrainer>|

## <a name="naive-bayes"></a><span data-ttu-id="61cae-204">Naive Bayes</span><span class="sxs-lookup"><span data-stu-id="61cae-204">Naive Bayes</span></span>

|<span data-ttu-id="61cae-205">属性</span><span class="sxs-lookup"><span data-stu-id="61cae-205">Properties</span></span>|<span data-ttu-id="61cae-206">训练程序</span><span class="sxs-lookup"><span data-stu-id="61cae-206">Trainers</span></span>|
|----------|--------|
|<span data-ttu-id="61cae-207">当特征独立且训练数据集很小时，请使用此多类分类训练程序。</span><span class="sxs-lookup"><span data-stu-id="61cae-207">Use this multi-class classification trainer when the features are independent, and the training dataset is small.</span></span>|<xref:Microsoft.ML.Trainers.NaiveBayesMulticlassTrainer>|

## <a name="prior-trainer"></a><span data-ttu-id="61cae-208">前期训练程序</span><span class="sxs-lookup"><span data-stu-id="61cae-208">Prior Trainer</span></span>

|<span data-ttu-id="61cae-209">属性</span><span class="sxs-lookup"><span data-stu-id="61cae-209">Properties</span></span>|<span data-ttu-id="61cae-210">训练程序</span><span class="sxs-lookup"><span data-stu-id="61cae-210">Trainers</span></span>|
|----------|--------|
|<span data-ttu-id="61cae-211">使用此二元分类训练程序来确定其他训练程序的性能基线。</span><span class="sxs-lookup"><span data-stu-id="61cae-211">Use this binary classification trainer to baseline the performance of other trainers.</span></span> <span data-ttu-id="61cae-212">其他训练程序的指标应优于前期训练程序才能成为有效指标。</span><span class="sxs-lookup"><span data-stu-id="61cae-212">To be effective, the metrics of the other trainers should be better than the prior trainer.</span></span> |<xref:Microsoft.ML.Trainers.PriorTrainer>|
